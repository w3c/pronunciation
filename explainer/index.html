<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<title>Explainer: Improving Spoken Presentation on the Web</title>
		<meta charset="utf-8"/>
		<script src="https://www.w3.org/Tools/respec/respec-w3c" class="remove"></script>
		
		<script src="respec-config.js" class="remove"></script>

	</head>
	<body>

		<section id="abstract">
            
            
			<p>The objective of the Pronunciation Task Force is to develop normative specifications and best practices guidance collaborating with other W3C groups as appropriate, to provide for proper pronunciation in HTML content when using text to speech (TTS) synthesis.  This document defines a standard mechanism to allow 
				content authors to include spoken presentation guidance in HTML content.</p>

		</section>

		<section id="sotd"></section>

		<section class="informative" id="introduction">

			<h1>Introduction</h1>
			<p>Accurate, consistent pronunciation and presentation of content spoken by text-to-speech (TTS) synthesis is an essential requirement in education, 
				communication, entertainment, and other domains. 
				From helping to teach spelling and pronunciation in different languages, to reading learning materials or new stories,
				TTS has become a vital technology for providing access to digital content on the web, through mobile devices, and now via voice-based assistants. 
				Organizations such as educational publishers and assessment vendors are looking for a standards-based solution to 
				enable authoring of spoken presentation guidance in HTML which can then be consumed by assistive technologies (AT) and other 
				applications that utilize text to speech synthesis (TTS) for rendering of content. 
				Historically, efforts at standardization (e.g. SSML or CSS Speech) have not led to broad adoption of any standard by user agents, authors, or AT; 
				what has arisen are a variety of non-interoperable approaches that meet specific needs for some applications. This explainer document presents the case for 
			improving spoken presentation on the Web and how a standards-based approach can address the requirements.</p>
	

		</section>
		<section>
			<h1>What is this?</h1>
			<p>This is a proposal for a mechanism to allow content authors to include spoken presentation guidance in HTML content.  Such guidance can be used by AT (including screen readers and read aloud tools) and voice assistants to control TTS synthesis. A key requirement is to ensure the spoken presentation content matches the author's intent and user expectations.</p>
			<p>The challenge is integrating pronunciation content into HTML so that it is easy to author, does not "break" content, and is straightforward for consumption by AT, voice assistants, and other tools that produce spoken presentation of content.</p>
		</section>
		<section>
			<h1>Why do we care?</h1>
			<p>Several classes of AT users depend upon spoken rendering of web content by TTS synthesis. In contexts such as education, there are specific expectations for accuracy of spoken presentation in terms of pronunciation, emphasis, prosody, pausing, etc.</p>
			<p>Correct pronunciation is also important in the context of language learning, where incorrect pronunciation can confuse learners.</p>
			<p>In practice, the ecosystem of devices used in classrooms is broad, and each vendor generally provides their own TTS engines for their platforms.  Ensuring consistent spoken presentation across devices is a very real problem, and challenge. For many educational assessment vendors, the problem necessitates non-interoperable hacks to tune pronunciation and other presentation features, such as pausing, which itself can introduce new problems through inconsistent representation of text across speech and braille.</p>
			<p>It could be argued that continual advances in machine learning will improve the quality of synthesized speech, reducing the need for this proposal. Waiting for a robust solution that will likely still not fully address our needs is risky, especially when an authorable, declarative approach may be within reach (and wouldn't preclude or conflict with continual improvement in TTS technology).</p>
			<p>The current situation:</p>
			<ul>
				<li>Is an authoring challenge for content developers that wish to support spoken presentation</li>
				<li>Limits interoperability and exchange of content between vendors and platforms</li>
				<li>Is an implementation challenge for developers creating AT and read aloud capabilities</li>
				<li>Presents an inconsistent, potentially confusing user experience for listeners of TTS</li>
			</ul>
			<p>With the growing consumer adoption of voice assistants, user expectations for high quality spoken presentation is growing.  Google and Amazon both encourage application developers to utilize SSML to enhance the user experience on their platforms, yet Web content authors do not have the same opportunity to enhance the spoken presentation of their content.</p>
			<p>Finding a solution to this need can have broader benefit in allowing authors to create web content that presents a better user experience if the content is presented by voice assistants.</p>
		</section>
		<section>
			<h1>Goals</h1>
			<ul>
				<li>Define a standard mechanism that enables spoken presentation guidance to be authored in HTML</li>
				<li>Leverage existing specifications, if possible</li>
				<li>The mechanism must be consumable by AT such as screen readers</li>
				<li>Address use cases with features, not a unified specification that attempts to cover all scenarios</li>
			</ul>
		</section>
		<section>
			<h2>Open Questions</h2>
			<ol>
				<li>What is the best approach to authoring spoken presentation guidance in HTML?  Possible approaches include:
					<ul>
						<li>Using existing elements and attributes in HTML (e.g. <code>&lt;span&gt;</code> with ARIA attributes)</li>
						<li>Defining new elements and/or attributes in HTML</li>
						<li>Using an existing specification such as SSML or CSS Speech within HTML</li>
					</ul>
				</li>
				<li>What spoken presentation features should be supported in the initial version of the specification?</li>
				<li>How to ensure that the mechanism is easy to author, does not "break" content, and is straightforward for consumption by AT and other tools that produce spoken presentation of content?</li>
			</ol>
		</section>


		



		<div data-include="../common/acknowledgements.html" data-oninclude="fixIncludes" data-include-replace="true">Acknowledgements placeholder</div>



	</body>
</html>
